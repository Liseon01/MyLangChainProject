{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f85708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 문제 4-1 Tool Calling 체인 테스트 시작 =====\n",
      "\n",
      "[테스트 1] 질문: 카푸치노의 가격과 특징은 무엇인가요?\n",
      "\n",
      "== 최종 답변 ==\n",
      "카푸치노의 가격은 ₩5,000입니다. 주요 원료는 에스프레소, 스팀 밀크, 우유 거품이며, 이탈리아 전통 커피로 에스프레소, 스팀 밀크, 우유 거품이 1:1:1 비율로 구성되어 있습니다. 진한 커피 맛과 부드러운 우유 거품의 조화가 특징이며, 계피 파우더를 뿌려 제공합니다.\n",
      "\n",
      "[테스트 2] 질문: 카푸치노의 유래에 대해서 알려주세요.\n",
      "\n",
      "== 최종 답변 ==\n",
      "카푸치노의 유래에 대한 정보는 제공할 수 없습니다. 다른 질문이 있으시면 말씀해 주세요.\n",
      "\n",
      "[테스트 3] 질문: 2024년 최신 커피 트렌드는 무엇인가요?\n",
      "\n",
      "== 최종 답변 ==\n",
      "2024년 커피 트렌드는 '투게더(TOGETHER)'로 선정되었습니다. 이 키워드는 커피의 생산과 유통 과정에서 다양한 요소가 서로 화합하고 상생하는 모습을 강조합니다. 서울카페쇼에서는 지속 가능한 카페 산업의 성장을 위한 방향성을 제시하며, 맞춤형 경험을 제공하는 브랜드가 증가하고 있습니다. 소비자들은 개인의 취향을 나노 단위로 분석하고, 다국적 메뉴와 문화 이벤트를 즐기는 경향이 높아지고 있습니다. 또한, 반려동물 친화적인 카페가 늘어나고 있으며, 대표적인 프랜차이즈 카페들이 새로운 라이프스타일을 반영한 매장을 확대하고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv; load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"db/cafe_db\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    from langchain_core.tools import tool\n",
    "    from langchain_core.runnables import chain\n",
    "    from langchain_core.documents import Document\n",
    "    from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_community.tools import TavilySearchResults\n",
    "except Exception:\n",
    "    tool, chain, Document, ChatOpenAI, OpenAIEmbeddings, FAISS, TavilySearchResults = [None] * 7\n",
    "\n",
    "try:\n",
    "    import wikipedia\n",
    "    wikipedia.set_lang(\"ko\")\n",
    "except Exception:\n",
    "    wikipedia = None\n",
    "\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "DB_DIR = BASE_DIR / \"db\" / \"cafe_db\"\n",
    "MENU_FILE = DATA_DIR / \"cafe_menu_data.txt\" \n",
    "\n",
    "def _read_menu_raw_content() -> str:\n",
    "    \"\"\"메뉴 파일을 읽고 단일 raw string으로 반환 (경로 탐색 강화)\"\"\"\n",
    "    candidates = [\n",
    "        MENU_FILE, \n",
    "        Path.cwd() / \"data\" / \"cafe_menu_data.txt\",\n",
    "        Path(__file__).resolve().parent / \"data\" / \"cafe_menu_data.txt\" if '__file__' in locals() or '__file__' in globals() else None\n",
    "    ]\n",
    "    for p in [c for c in candidates if c]:\n",
    "        if p.exists():\n",
    "            return p.read_text(encoding=\"utf-8\")\n",
    "            \n",
    "    raise FileNotFoundError(\n",
    "        \"메뉴 파일 누락: './data/cafe_menu_data.txt' 파일을 찾을 수 없습니다. 경로를 확인하세요.\"\n",
    "    )\n",
    "\n",
    "def _split_menu_by_number(raw_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    강화된 정규식을 사용하여 메뉴 번호(1., 2., ...)를 기준으로 항목을 분리합니다.\n",
    "    \"\"\"\n",
    "    normalized_text = raw_text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    pattern = r'(\\d+\\.\\s*.*?)((?=\\n\\d+\\.)|\\Z)'\n",
    "    \n",
    "    menu_items_tuples = re.findall(pattern, normalized_text, re.DOTALL)\n",
    "    menu_items = [item[0].strip() for item in menu_items_tuples if item[0].strip()]\n",
    "\n",
    "    if not menu_items or len(menu_items) < 3:\n",
    "        raise ValueError(f\"메뉴 분리에 실패했습니다. 분리된 항목 수: {len(menu_items)}. 파일 형식을 확인하세요.\")\n",
    "        \n",
    "    return menu_items\n",
    "\n",
    "def _ensure_vector_db() -> \"FAISS\":\n",
    "    \"\"\"FAISS DB를 생성하고 저장합니다. (save_local 인자 수정)\"\"\"\n",
    "    if not all([FAISS, OpenAIEmbeddings, Document]):\n",
    "        raise RuntimeError(\"DB 의존성(FAISS/OpenAIEmbeddings)이 부족합니다.\")\n",
    "    \n",
    "    raw_content = _read_menu_raw_content()\n",
    "    lines = _split_menu_by_number(raw_content) \n",
    "    \n",
    "    DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    docs = []\n",
    "    for i, line in enumerate(lines, start=1):\n",
    "        parts = line.split('\\n', 1)\n",
    "        menu_name = re.sub(r'^\\d+\\.\\s*', '', parts[0].strip()).strip()\n",
    "        docs.append(Document(page_content=line, metadata={\"name\": menu_name or f\"item_{i}\"}))\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectordb = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    vectordb.save_local(str(DB_DIR)) \n",
    "    print(f\"DB 생성 완료: 총 {len(docs)}개 항목\")\n",
    "    return vectordb\n",
    "\n",
    "def _load_vector_db() -> \"FAISS\":\n",
    "    \"\"\"FAISS DB를 로드하며, 없으면 새로 생성합니다. (load_local 인자 유지)\"\"\"\n",
    "    if not all([FAISS, OpenAIEmbeddings]):\n",
    "        raise RuntimeError(\"DB 로드 의존성(FAISS/OpenAIEmbeddings)이 부족합니다.\")\n",
    "        \n",
    "    if not (DB_DIR / \"index.faiss\").exists():\n",
    "        return _ensure_vector_db()\n",
    "        \n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "   \n",
    "    return FAISS.load_local(str(DB_DIR), embeddings, allow_dangerous_deserialization=True) \n",
    "\n",
    "_TAVILY_TOOL_OBJ = TavilySearchResults(max_results=3, search_depth=\"advanced\") if TavilySearchResults else None\n",
    "\n",
    "if tool is not None and wikipedia is not None:\n",
    "    @tool\n",
    "    def wiki_summary(topic: str) -> str:\n",
    "        \"\"\"위키피디아에서 일반 지식(예: 커피 역사, 제조 방법)을 검색하고 요약해야 할 때 사용하세요.\"\"\"\n",
    "        try:\n",
    "            return wikipedia.summary(topic, sentences=3, auto_suggest=False, redirect=True)\n",
    "        except Exception as e:\n",
    "            return f\"Wikipedia 검색 오류: {e}\"\n",
    "else:\n",
    "    def wiki_summary(topic: str) -> str:\n",
    "        return \"Wikipedia 툴 비활성화.\"\n",
    "\n",
    "if tool is not None:\n",
    "    @tool\n",
    "    def db_search_cafe_func(query: str) -> List[\"Document\"]:\n",
    "        \"\"\"로컬 카페 메뉴 DB에서 특정 메뉴의 가격, 재료, 설명과 같은 정보를 검색해야 할 때 사용하세요.\"\"\"\n",
    "        try:\n",
    "            vectordb = _load_vector_db()\n",
    "            retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "            return retriever.invoke(query)\n",
    "        except Exception as e:\n",
    "            print(f\"경고: DB 검색 실패 ({e}). 파일 내용으로 폴백합니다.\")\n",
    "            try:\n",
    "                lines = _split_menu_by_number(_read_menu_raw_content())\n",
    "                q_compact = query.replace(\" \", \"\")\n",
    "                matched = [ln for ln in lines if q_compact in ln.replace(\" \", \"\")]\n",
    "                return [Document(page_content=ln, metadata={}) for ln in matched]\n",
    "            except Exception:\n",
    "                return []\n",
    "else:\n",
    "    def db_search_cafe_func(query: str) -> List[str]:  # type: ignore\n",
    "        return []\n",
    "\n",
    "def _make_llm_with_tools():\n",
    "    \"\"\"도구가 바인딩된 LLM 생성.\"\"\"\n",
    "    if not all([ChatOpenAI, OPENAI_API_KEY]): return None, []\n",
    "        \n",
    "    llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "    tools = [t for t in [_TAVILY_TOOL_OBJ, wiki_summary, db_search_cafe_func] if t is not None]\n",
    "    \n",
    "    try:\n",
    "        llm_with_tools = llm.bind_tools(tools)\n",
    "    except Exception:\n",
    "        llm_with_tools = None\n",
    "        \n",
    "    return llm_with_tools, tools\n",
    "\n",
    "def _make_llm_text_only():\n",
    "    \"\"\"최종 답변을 위한 툴이 없는 순수 텍스트 LLM 생성.\"\"\"\n",
    "    if not all([ChatOpenAI, OPENAI_API_KEY]): return None\n",
    "    return ChatOpenAI(model=OPENAI_MODEL, temperature=0)\n",
    "\n",
    "def _format_docs(docs: List[Any]) -> str:\n",
    "    \"\"\"Document 객체를 읽기 쉬운 텍스트로 변환\"\"\"\n",
    "    chunks = [getattr(d, \"page_content\", str(d)) for d in docs]\n",
    "    return \"\\n===\\n\".join(chunks)\n",
    "\n",
    "def _compose_answer_from_db(db_output: str, question: str) -> str:\n",
    "    \"\"\"DB 결과에서 가격, 재료, 특징을 추출하여 답변 (LLM 실패 시 폴백)\"\"\"\n",
    "    first_item = db_output.split(\"\\n===\\n\")[0].strip()\n",
    "    if not first_item: return \"메뉴 DB에서 관련 정보를 찾지 못했습니다.\"\n",
    "        \n",
    "    menu_match = re.search(r'^\\d+\\.\\s*(.*?)\\n', first_item, re.MULTILINE)\n",
    "    price_match = re.search(r'•\\s*가격:\\s*(₩[\\d,]+)', first_item)\n",
    "    ingredients_match = re.search(r'•\\s*주요 원료:\\s*(.*?)\\n', first_item)\n",
    "    desc_match = re.search(r'•\\s*설명:\\s*(.*?)(?=\\n\\d+\\.|\\Z)', first_item, re.DOTALL)\n",
    "    \n",
    "    menu_name = menu_match.group(1).strip() if menu_match else \"요청 메뉴\"\n",
    "    parts = []\n",
    "    if price_match: parts.append(f\"가격: {price_match.group(1)}\")\n",
    "    if ingredients_match: parts.append(f\"주요 재료: {ingredients_match.group(1).strip()}\")\n",
    "    if desc_match: \n",
    "        desc_text = desc_match.group(1).strip().replace('\\n', ' ')\n",
    "        parts.append(f\"특징: {desc_text}\")\n",
    "    \n",
    "    return f\"'{menu_name}'의 정보입니다.\\n\" + \" / \".join(parts)\n",
    "\n",
    "def _safe_tool_invoke(tool_obj: Any, name: str, args: Any, question: str) -> Dict[str, Any]:\n",
    "    \"\"\"개별 툴을 안전하게 실행하고 결과를 딕셔너리로 반환\"\"\"\n",
    "    try:\n",
    "        q = (args or {}).get(\"query\", question) if isinstance(args, dict) else question\n",
    "        \n",
    "        if name == \"db_search_cafe_func\":\n",
    "            out_docs = tool_obj.invoke(q)\n",
    "            out = _format_docs(out_docs)\n",
    "        elif name == \"wiki_summary\":\n",
    "            query_arg = (args or {}).get(\"topic\", q) if isinstance(args, dict) else q\n",
    "            out = tool_obj.invoke(query_arg)\n",
    "        elif name in [\"tavily_search_results_json\", \"TavilySearchResults\"]:\n",
    "            out = tool_obj.invoke({\"query\": q})\n",
    "        else:\n",
    "            out = tool_obj.invoke(q)\n",
    "             \n",
    "        return {\"tool\": name, \"output\": out}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"tool\": name, \"output\": f\"ERROR: 툴 실행 실패 - {e}\"}\n",
    "\n",
    "if chain is not None and ChatOpenAI is not None:\n",
    "    @chain\n",
    "    def tool_calling_chain(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        question = inputs[\"question\"]\n",
    "        \n",
    "        if OPENAI_API_KEY is None:\n",
    "            return {\"answer\": \"OpenAI API 키가 설정되지 않아 답변을 생성할 수 없습니다.\", \"tool_outputs\": []}\n",
    "\n",
    "        llm_with_tools, tools = _make_llm_with_tools()\n",
    "        registry: Dict[str, Any] = {\n",
    "            getattr(t, \"name\", getattr(t, \"__name__\", None)): t for t in tools if getattr(t, \"name\", getattr(t, \"__name__\", None))\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            ai_msg = llm_with_tools.invoke([HumanMessage(content=question)])\n",
    "        except Exception as e:\n",
    "            return {\"answer\": f\"LLM 호출 오류 발생: {e}\", \"tool_outputs\": []}\n",
    "            \n",
    "        tool_outputs = []\n",
    "        calls = getattr(ai_msg, \"tool_calls\", []) or []\n",
    "\n",
    "        for call in calls:\n",
    "            name = getattr(call, \"name\", None) or (call.get(\"name\") if isinstance(call, dict) else None)\n",
    "            args = getattr(call, \"args\", {})\n",
    "            tool_obj = registry.get(name)\n",
    "            \n",
    "            if tool_obj:\n",
    "                tool_outputs.append(_safe_tool_invoke(tool_obj, name, args, question))\n",
    "\n",
    "        has_db = any(o.get(\"tool\") == \"db_search_cafe_func\" for o in tool_outputs)\n",
    "        if (\"가격\" in question or \"메뉴\" in question or \"특징\" in question or \"재료\" in question) and not has_db:\n",
    "            db_obj = registry.get(\"db_search_cafe_func\")\n",
    "            if db_obj:\n",
    "                print(\"정보 보강: DB 검색 결과 강제 추가\")\n",
    "                tool_outputs.append(_safe_tool_invoke(db_obj, \"db_search_cafe_func\", {}, question))\n",
    "        \n",
    "        llm_text = _make_llm_text_only()\n",
    "        evidence = json.dumps(tool_outputs, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        final_prompt = (\n",
    "            \"당신은 카페 메뉴 안내 AI입니다. 다음 도구 실행 결과를 바탕으로 질문에 한국어로 정확히 답하세요.\\n\"\n",
    "            \"가격(₩ 표기), 재료, 특징을 포함해 간결하게 정리하세요. 추측하지 말고 도구 결과만 사용하세요.\\n\"\n",
    "            \"답변은 텍스트로만 출력하세요. 도구를 호출하지 마세요.\\n\"\n",
    "            f\"질문: {question}\\n\"\n",
    "            f\"도구결과(JSON):\\n{evidence}\\n\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            final_msg = llm_text.invoke(final_prompt)\n",
    "            content = getattr(final_msg, \"content\", None)\n",
    "            \n",
    "            if not content:\n",
    "                content = _compose_answer_from_db(evidence, question)\n",
    "                \n",
    "            return {\"answer\": content, \"tool_outputs\": tool_outputs}\n",
    "            \n",
    "        except Exception:\n",
    "\n",
    "            content = _compose_answer_from_db(evidence, question)\n",
    "            return {\"answer\": content + \" (LLM 최종 생성 실패로 DB 답변으로 대체됨)\", \"tool_outputs\": tool_outputs}\n",
    "\n",
    "else:\n",
    "\n",
    "    def tool_calling_chain(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return {\"answer\": \"핵심 종속성이 부족하여 체인을 실행할 수 없습니다.\", \"tool_outputs\": []}\n",
    "\n",
    "\n",
    "def run_test():\n",
    "    print(\"===== 문제 4-1 Tool Calling 체인 테스트 시작 =====\")\n",
    "    \n",
    "    question_db = \"카푸치노의 가격과 특징은 무엇인가요?\"\n",
    "    print(f\"\\n[테스트 1] 질문: {question_db}\")\n",
    "    result_db = tool_calling_chain.invoke({\"question\": question_db})\n",
    "    print(\"\\n== 최종 답변 ==\")\n",
    "    print(result_db.get(\"answer\", \"\"))\n",
    "    \n",
    "    question_wiki = \"카푸치노의 유래에 대해서 알려주세요.\"\n",
    "    print(f\"\\n[테스트 2] 질문: {question_wiki}\")\n",
    "    result_wiki = tool_calling_chain.invoke({\"question\": question_wiki})\n",
    "    print(\"\\n== 최종 답변 ==\")\n",
    "    print(result_wiki.get(\"answer\", \"\"))\n",
    "\n",
    "    question_web = \"2024년 최신 커피 트렌드는 무엇인가요?\"\n",
    "    print(f\"\\n[테스트 3] 질문: {question_web}\")\n",
    "    result_web = tool_calling_chain.invoke({\"question\": question_web})\n",
    "    print(\"\\n== 최종 답변 ==\")\n",
    "    print(result_web.get(\"answer\", \"\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        _load_vector_db() \n",
    "    except FileNotFoundError as e:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"FATAL: 메뉴 파일을 찾을 수 없습니다.\")\n",
    "        print(f\"오류: {e}\")\n",
    "        print(\"파일명을 'cafe_menu_data.txt'로 변경하고 './data' 폴더에 저장했는지 확인하세요.\")\n",
    "        print(\"=\" * 50)\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"FATAL: DB 구축 실패 (데이터 형식 또는 기타 오류)\")\n",
    "        print(f\"오류: {e}\")\n",
    "        print(\"\\n'cafe_menu_data.txt' 파일 내용이 메뉴 번호(1., 2., 3. ...)로 시작하는지, 그리고 패키지(FAISS 등)가 정상 설치되었는지 확인하세요.\")\n",
    "        print(\"=\" * 50)\n",
    "        exit(1)\n",
    "    \n",
    "    if ChatOpenAI is not None and OPENAI_API_KEY is not None:\n",
    "        run_test()\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\" OpenAI API 키 누락 또는 LangChain/OpenAI 패키지 미설치\")\n",
    "        print(\"API 키를 환경 변수에 설정하거나, 필요한 패키지를 설치하세요.\")\n",
    "        print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
