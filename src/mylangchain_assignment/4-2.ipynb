{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector DB ë¡œë“œ ì™„ë£Œ.\n",
      "\n",
      "==================================================\n",
      "LangGraph ê¸°ë°˜ ë©”ë‰´ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ê°€ê²© ì •í™•ë„ ê°œì„ )\n",
      "==================================================\n",
      "ğŸ™‹â€â™‚ï¸ Q1 (ê°€ê²©/ë©”ë‰´): ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ê³¼ ì£¼ìš” íŠ¹ì§•ì„ ìì„¸íˆ ì•Œë ¤ì¤„ë˜?\n",
      "ë¶„ë¥˜ ê²°ê³¼: price_specific\n",
      "ê²€ìƒ‰ ì¿¼ë¦¬: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ê³¼ ì£¼ìš” íŠ¹ì§•ì„ ìì„¸íˆ ì•Œë ¤ì¤„ë˜?\n",
      "ğŸ¤– A1: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ì€ â‚©4,500ì…ë‹ˆë‹¤. ì´ ìŒë£ŒëŠ” ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ëœ¨ê±°ìš´ ë¬¼ì„ ë”í•´ ë§Œë“  í´ë˜ì‹í•œ ë¸”ë™ ì»¤í”¼ë¡œ, ì›ë‘ ë³¸ì—°ì˜ ë§›ì„ ê°€ì¥ ì˜ ëŠë‚„ ìˆ˜ ìˆëŠ” ìŒë£Œì…ë‹ˆë‹¤. ê¹”ë”í•˜ê³  ê¹Šì€ í’ë¯¸ê°€ íŠ¹ì§•ì´ë©°, ì›í•˜ì‹ ë‹¤ë©´ ì„¤íƒ•ì´ë‚˜ ì‹œëŸ½ì„ ì¶”ê°€í•˜ì—¬ ë“œì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì»¤í”¼ì˜ ì§„í•œ ë§›ì„ ì¦ê¸°ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ ì•„ë©”ë¦¬ì¹´ë…¸ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!\n",
      "\n",
      "ğŸ™‹â€â™‚ï¸ Q2 (ì¶”ì²œ ìš”ì²­): ìš”ì¦˜ ì¸ê¸° ìˆëŠ” ë©”ë‰´ ì¤‘ì—ì„œ ë‹¬ì½¤í•˜ê³  ì‹œì›í•œ ê±¸ë¡œ í•˜ë‚˜ ì¶”ì²œí•´ ì¤˜.\n",
      "ë¶„ë¥˜ ê²°ê³¼: recommend\n",
      "ê²€ìƒ‰ ì¿¼ë¦¬: ìš”ì¦˜ ì¸ê¸° ìˆëŠ” ë©”ë‰´ ì¤‘ì—ì„œ ë‹¬ì½¤í•˜ê³  ì‹œì›í•œ ê±¸ë¡œ í•˜ë‚˜ ì¶”ì²œí•´ ì¤˜. ì¸ê¸° ë©”ë‰´\n",
      "ğŸ¤– A2: ìš”ì¦˜ ì¸ê¸° ìˆëŠ” ë©”ë‰´ ì¤‘ì—ì„œ ë‹¬ì½¤í•˜ê³  ì‹œì›í•œ ê²ƒì„ ì°¾ìœ¼ì‹ ë‹¤ë©´ **í”„ë¼í‘¸ì¹˜ë…¸**ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤! ì´ ìŒë£ŒëŠ” ì—ìŠ¤í”„ë ˆì†Œì™€ ìš°ìœ , ì–¼ìŒì„ ë¸”ë Œë”ì— ê°ˆì•„ ë§Œë“  ì‹œì›í•œ ìŒë£Œë¡œ, ë¶€ë“œëŸ½ê³  í¬ë¦¬ë¯¸í•œ ì§ˆê°ì´ íŠ¹ì§•ì…ë‹ˆë‹¤. ë˜í•œ íœ˜í•‘í¬ë¦¼ì´ ì˜¬ë¼ê°€ ìˆì–´ ë”ìš± ë‹¬ì½¤í•œ ë§›ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ë¦„ì² ì— íŠ¹íˆ ì¸ê¸° ìˆëŠ” ë©”ë‰´ì´ë‹ˆ, ì‹œì›í•˜ê²Œ ì¦ê¸°ê¸°ì— ì•ˆì„±ë§ì¶¤ì…ë‹ˆë‹¤! ê°€ê²©ì€ â‚©7,000ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ™‹â€â™‚ï¸ Q3 (ì¼ë°˜ ê°€ê²© ë¬¸ì˜): ê·¸ëŸ¼ ë‚´ê°€ ì¶”ì²œ ë°›ì€ ë©”ë‰´ ê°€ê²©ì€ ì–¼ë§ˆì•¼?\n",
      "ë¶„ë¥˜ ê²°ê³¼: price_general\n",
      "ê²€ìƒ‰ ì¿¼ë¦¬: ëª¨ë“  ë©”ë‰´ ê°€ê²© ëª©ë¡\n",
      "ğŸ¤– A3: ì¶”ì²œ ë°›ì€ ë©”ë‰´ì˜ ê°€ê²©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "- ë°”ë‹ë¼ ë¼ë–¼: â‚©6,000\n",
      "- ì¹´í˜ë¼ë–¼: â‚©5,500\n",
      "- í‹°ë¼ë¯¸ìˆ˜: â‚©7,500\n",
      "- ë…¹ì°¨ ë¼ë–¼: â‚©5,800\n",
      "- ì•„ë©”ë¦¬ì¹´ë…¸: â‚©4,500\n",
      "\n",
      "ì›í•˜ì‹œëŠ” ë©”ë‰´ì˜ ê°€ê²©ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "==================================================\n",
      "í…ŒìŠ¤íŠ¸ ì¢…ë£Œ (ëŒ€í™” ID: user-cafe-003)\n",
      "íŠ¹ì • ë©”ë‰´ ê°€ê²© ë¬¸ì˜ì— ëŒ€í•œ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤. ğŸš€\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, Annotated, List, Any\n",
    "from operator import itemgetter\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv; load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    warnings.warn(\"OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. LLM í˜¸ì¶œì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BASE_DIR = Path(os.getcwd())\n",
    "DB_DIR = BASE_DIR / \"db\" / \"cafe_db\"\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    query_type: str \n",
    "    db_result: str \n",
    "    \n",
    "def load_db_instance() -> FAISS:\n",
    "    if not all([FAISS, OpenAIEmbeddings]):\n",
    "        raise RuntimeError(\"FAISS ë˜ëŠ” OpenAIEmbeddings íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    db_path = str(DB_DIR)\n",
    "    if not (DB_DIR / \"index.faiss\").exists():\n",
    "        raise FileNotFoundError(f\"DB íŒŒì¼ì´ {db_path}ì— ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    return FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "try:\n",
    "    menu_db = load_db_instance()\n",
    "    print(\"Vector DB ë¡œë“œ ì™„ë£Œ.\")\n",
    "except Exception as e:\n",
    "    print(f\"DB ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    menu_db = None\n",
    "\n",
    "def extract_menu_info(doc: Document) -> dict:\n",
    "    content = doc.page_content\n",
    "    menu_name = doc.metadata.get('name', 'Unknown')\n",
    "    price_match = re.search(r'^\\s*â€¢\\s*ê°€ê²©:\\s*(â‚©[\\d,]+)', content, re.MULTILINE)\n",
    "    description_match = re.search(r'â€¢\\s*ì„¤ëª…:\\s*(.+?)(?:\\n\\s*â€¢|\\Z)', content, re.DOTALL)\n",
    "    return {\n",
    "        \"name\": menu_name,\n",
    "        \"price\": price_match.group(1) if price_match else \"ê°€ê²© ì •ë³´ ì—†ìŒ\", \n",
    "        \"description\": description_match.group(1).strip().replace('\\n', ' ') if description_match else \"ì„¤ëª… ì—†ìŒ\"\n",
    "    }\n",
    "\n",
    "def detect_specific_menu(message: str) -> str | None:\n",
    "    menu_keywords = [\"ì•„ë©”ë¦¬ì¹´ë…¸\", \"ì¹´í˜ë¼ë–¼\", \"ì¹´í‘¸ì¹˜ë…¸\", \"ë°”ë‹ë¼ ë¼ë–¼\", \"ì¹´ë¼ë©œ ë§ˆí‚¤ì•„í† \", \"ì½œë“œë¸Œë£¨\", \"í”„ë¼í‘¸ì¹˜ë…¸\", \"ë…¹ì°¨ ë¼ë–¼\", \"í‹°ë¼ë¯¸ìˆ˜\"]\n",
    "    for keyword in menu_keywords:\n",
    "        if keyword.lower() in message.lower():\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "def classify_query(state: GraphState) -> GraphState:\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    user_message_lower = user_message.lower()\n",
    "    detected_menu = detect_specific_menu(user_message)\n",
    "    if \"ê°€ê²©\" in user_message_lower or \"ì–¼ë§ˆ\" in user_message_lower:\n",
    "        if detected_menu:\n",
    "            query_type = \"price_specific\" \n",
    "        else:\n",
    "            query_type = \"price_general\" \n",
    "    elif \"ì¶”ì²œ\" in user_message_lower or \"ë­ ë§ˆì‹¤ê¹Œ\" in user_message_lower:\n",
    "        query_type = \"recommend\"\n",
    "    elif \"ë©”ë‰´\" in user_message_lower or \"ìˆì–´\" in user_message_lower or \"ì¢…ë¥˜\" in user_message_lower:\n",
    "        query_type = \"menu\"\n",
    "    else:\n",
    "        query_type = \"unknown\"\n",
    "    print(f\"ë¶„ë¥˜ ê²°ê³¼: {query_type}\")\n",
    "    return {\"query_type\": query_type}\n",
    "\n",
    "def execute_search(state: GraphState) -> GraphState:\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    query_type = state[\"query_type\"]\n",
    "    if menu_db is None:\n",
    "        return {\"db_result\": \"Vector DBë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ê²€ìƒ‰ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\"}\n",
    "    if query_type == \"price_specific\":\n",
    "        query = user_message\n",
    "        k = 1\n",
    "    elif query_type == \"price_general\":\n",
    "        query = \"ëª¨ë“  ë©”ë‰´ ê°€ê²© ëª©ë¡\"\n",
    "        k = 5\n",
    "    elif query_type == \"recommend\":\n",
    "        query = f\"{user_message} ì¸ê¸° ë©”ë‰´\"\n",
    "        k = 3\n",
    "    elif query_type == \"menu\":\n",
    "        query = user_message\n",
    "        k = 4\n",
    "    else:\n",
    "        query = user_message\n",
    "        k = 3\n",
    "    print(f\"ê²€ìƒ‰ ì¿¼ë¦¬: {query}\")\n",
    "    docs = menu_db.similarity_search(query, k=k)\n",
    "    search_results = []\n",
    "    for doc in docs:\n",
    "        info = extract_menu_info(doc)\n",
    "        search_results.append(\n",
    "            f\"ë©”ë‰´: {info['name']}, ê°€ê²©: {info['price']}, íŠ¹ì§•: {info['description']}\"\n",
    "        )\n",
    "    return {\"db_result\": \"\\n\".join(search_results)}\n",
    "\n",
    "def generate_response(state: GraphState) -> GraphState:\n",
    "    db_result = state[\"db_result\"]\n",
    "    chat_history = state[\"messages\"]\n",
    "    query_type = state[\"query_type\"]\n",
    "    if db_result.startswith(\"Vector DBë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´\"):\n",
    "        ai_content = \"ì£„ì†¡í•´ìš”. í˜„ì¬ ë©”ë‰´ DBì— ì ‘ê·¼í•  ìˆ˜ ì—†ì–´ ì •í™•í•œ ì •ë³´ë¥¼ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        return {\"messages\": [AIMessage(content=ai_content)]}\n",
    "    if not all([ChatOpenAI, OPENAI_API_KEY]):\n",
    "        ai_content = f\"DB ê²€ìƒ‰ ê²°ê³¼: {db_result[:100]}... OpenAI í‚¤ê°€ ì—†ì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        return {\"messages\": [AIMessage(content=ai_content)]}\n",
    "    llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.2)\n",
    "    system_prompt = (\n",
    "        \"ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì¹´í˜ ë©”ë‰´ ì¶”ì²œ ë° ì•ˆë‚´ AIì…ë‹ˆë‹¤. \"\n",
    "        \"ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ì™€ ì´ì „ ëŒ€í™” ì´ë ¥ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°€ì¥ ì ì ˆí•˜ê³  ì¹œì ˆí•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ìƒì„±í•˜ì„¸ìš”. \"\n",
    "        \"ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”. \"\n",
    "        \"ë¬¸ì˜ ìœ í˜•ì€ '{query_type}'ì…ë‹ˆë‹¤.\"\n",
    "    )\n",
    "    final_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt.format(query_type=query_type)),\n",
    "        *chat_history,\n",
    "        (\"user\", f\"ìœ„ì— ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜. ê²€ìƒ‰ ê²°ê³¼:\\n{db_result}\"),\n",
    "    ])\n",
    "    response_chain = final_prompt | llm | StrOutputParser()\n",
    "    ai_content = response_chain.invoke({})\n",
    "    return {\"messages\": [AIMessage(content=ai_content)]}\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"classify\", classify_query)\n",
    "workflow.add_node(\"search\", execute_search)\n",
    "workflow.add_node(\"generate\", generate_response)\n",
    "workflow.set_entry_point(\"classify\")\n",
    "workflow.add_edge(\"classify\", \"search\")\n",
    "workflow.add_edge(\"search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "def run_conversation(prompt: str, app_instance, thread_id: str) -> str:\n",
    "    initial_state = {\"messages\": [HumanMessage(content=prompt)]}\n",
    "    final_state = app_instance.invoke(\n",
    "        initial_state,\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    final_message = final_state[\"messages\"][-1]\n",
    "    return final_message.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 50)\n",
    "    print(\"LangGraph ê¸°ë°˜ ë©”ë‰´ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "    conversation_id = \"user-cafe-003\" \n",
    "    q1 = \"ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ê³¼ ì£¼ìš” íŠ¹ì§•ì„ ìì„¸íˆ ì•Œë ¤ì¤„ë˜?\"\n",
    "    print(f\"Q1: {q1}\")\n",
    "    a1 = run_conversation(q1, app, conversation_id)\n",
    "    print(f\"A1: {a1}\")\n",
    "    q2 = \"ìš”ì¦˜ ì¸ê¸° ìˆëŠ” ë©”ë‰´ ì¤‘ì—ì„œ ë‹¬ì½¤í•˜ê³  ì‹œì›í•œ ê±¸ë¡œ í•˜ë‚˜ ì¶”ì²œí•´ ì¤˜.\"\n",
    "    print(f\"\\nQ2: {q2}\")\n",
    "    a2 = run_conversation(q2, app, conversation_id)\n",
    "    print(f\"A2: {a2}\")\n",
    "    q3 = \"ê·¸ëŸ¼ ë‚´ê°€ ì¶”ì²œ ë°›ì€ ë©”ë‰´ ê°€ê²©ì€ ì–¼ë§ˆì•¼?\"\n",
    "    print(f\"\\nQ3: {q3}\")\n",
    "    a3 = run_conversation(q3, app, conversation_id)\n",
    "    print(f\"A3: {a3}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ì¢…ë£Œ (ëŒ€í™” ID: {conversation_id})\")\n",
    "    print(\"=\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
